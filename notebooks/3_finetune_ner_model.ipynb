{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Fine-tune NER Model for Amharic Telegram Messages"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- The notebook demonstrates the fine-tuning of a BERT multilingual model for Named Entity Recognition (NER) on Ethiopian market data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Environment Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install required packages\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "def set_seed(seed=42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def set_seed(seed: int = 42):\n",
    "    \"\"\"Set random seed for reproducibility\"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "\n",
    "set_seed(42)\n",
    "\n",
    "from transformers import (\n",
    "    AutoTokenizer, \n",
    "    AutoModelForTokenClassification,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorForTokenClassification\n",
    ")\n",
    "from datasets import Dataset, DatasetDict\n",
    "import evaluate\n",
    "from seqeval.metrics import classification_report, f1_score, precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load & Rebalance CoNLL Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original entity counts: Counter({'I-LOC': 100, 'B-Product': 76, 'B-LOC': 50, 'B-PRICE': 44, 'I-Product': 16})\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "836d59a73ce84ec8857e69e75a937e17",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/50 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "from collections import Counter\n",
    "\n",
    "\n",
    "def read_conll(filepath):\n",
    "    data = []\n",
    "    tokens, ner_tags = [], []\n",
    "    with open(filepath, encoding=\"utf-8\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                if tokens:\n",
    "                    data.append({\"tokens\": tokens, \"ner_tags\": ner_tags})\n",
    "                    tokens, ner_tags = [], []\n",
    "            else:\n",
    "                token, tag = line.split()[0], line.split()[-1]\n",
    "                tokens.append(token)\n",
    "                ner_tags.append(tag)\n",
    "        if tokens:\n",
    "            data.append({\"tokens\": tokens, \"ner_tags\": ner_tags})\n",
    "    return data\n",
    "\n",
    "conll_path = \"../data/labeled/auto_ner_dataset.conll\"\n",
    "examples = read_conll(conll_path)\n",
    "\n",
    "# Optional Rebalancing Step\n",
    "entity_counts = Counter(tag for ex in examples for tag in ex[\"ner_tags\"] if tag != 'O')\n",
    "print(\"Original entity counts:\", entity_counts)\n",
    "\n",
    "# Balance dataset (if needed)\n",
    "def balance_dataset(data, target_count=50):\n",
    "    from collections import defaultdict\n",
    "    grouped = defaultdict(list)\n",
    "    for ex in data:\n",
    "        for tag in ex['ner_tags']:\n",
    "            if tag.startswith(\"B-\"):\n",
    "                grouped[tag].append(ex)\n",
    "                break\n",
    "    final = []\n",
    "    for tag, group in grouped.items():\n",
    "        final.extend(group[:target_count])\n",
    "    return final\n",
    "\n",
    "examples = balance_dataset(examples, target_count=50)\n",
    "dataset = Dataset.from_list(examples)\n",
    "\n",
    "# %%\n",
    "unique_tags = sorted(set(tag for example in dataset for tag in example['ner_tags']))\n",
    "label2id = {label: i for i, label in enumerate(unique_tags)}\n",
    "id2label = {i: label for label, i in label2id.items()}\n",
    "\n",
    "def encode_labels(example):\n",
    "    example['labels'] = [label2id[tag] for tag in example['ner_tags']]\n",
    "    return example\n",
    "\n",
    "dataset = dataset.map(encode_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tokenizer & Alignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Use a publicly available multilingual BERT model instead of the private Davlan model\n",
    "model_checkpoint = \"bert-base-multilingual-cased\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
    "\n",
    "\n",
    "def tokenize_and_align_labels(example):\n",
    "    tokenized = tokenizer(\n",
    "        example[\"tokens\"],\n",
    "        is_split_into_words=True,\n",
    "        truncation=True,\n",
    "        padding='max_length',\n",
    "        max_length=256,\n",
    "        return_offsets_mapping=True\n",
    "    )\n",
    "    labels = []\n",
    "    word_ids = tokenized.word_ids()\n",
    "    previous_word_idx = None\n",
    "    for word_idx in word_ids:\n",
    "        if word_idx is None:\n",
    "            labels.append(-100)\n",
    "        elif word_idx != previous_word_idx:\n",
    "            labels.append(example[\"labels\"][word_idx])\n",
    "        else:\n",
    "            labels.append(-100)\n",
    "        previous_word_idx = word_idx\n",
    "    tokenized[\"labels\"] = labels\n",
    "    return tokenized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Train/Val Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f09aca5e1df64f958a6da04dce027fdf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/40 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a510ce35fee9424cbbc7a5b93cd9ba6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/10 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Use the built-in train_test_split method from the dataset object\n",
    "split = dataset.train_test_split(test_size=0.2, seed=42)\n",
    "train_dataset = split['train']\n",
    "val_dataset = split['test']\n",
    "\n",
    "train_tokenized = train_dataset.map(tokenize_and_align_labels)\n",
    "val_tokenized = val_dataset.map(tokenize_and_align_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Model & Trainer Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForTokenClassification were not initialized from the model checkpoint at bert-base-multilingual-cased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification, DataCollatorForTokenClassification, TrainingArguments, Trainer\n",
    "import evaluate\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    num_labels=len(label2id),\n",
    "    id2label=id2label,\n",
    "    label2id=label2id\n",
    ")\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer)\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "\n",
    "def compute_metrics(p):\n",
    "    predictions, labels = p\n",
    "    predictions = np.argmax(predictions, axis=2)\n",
    "    true_preds = [[id2label[p] for (p, l) in zip(pred, label) if l != -100] for pred, label in zip(predictions, labels)]\n",
    "    true_labels = [[id2label[l] for (p, l) in zip(pred, label) if l != -100] for pred, label in zip(predictions, labels)]\n",
    "    results = metric.compute(predictions=true_preds, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": results[\"overall_precision\"],\n",
    "        \"recall\": results[\"overall_recall\"],\n",
    "        \"f1\": results[\"overall_f1\"],\n",
    "        \"accuracy\": results[\"overall_accuracy\"],\n",
    "    }\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"./models/finetuned_ner_amharic\",\n",
    "    num_train_epochs=8,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    "    learning_rate=3e-5,\n",
    "    eval_strategy=\"epoch\",\n",
    "    save_strategy=\"epoch\",\n",
    "    logging_dir=\"./logs\",\n",
    "    load_best_model_at_end=True,\n",
    "    metric_for_best_model=\"f1\",\n",
    "    greater_is_better=True,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_tokenized,\n",
    "    eval_dataset=val_tokenized,\n",
    "    data_collator=data_collator,\n",
    "    processing_class=tokenizer,\n",
    "    compute_metrics=compute_metrics\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Training & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='24' max='24' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [24/24 11:28, Epoch 8/8]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Epoch</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.938728</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.800853</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.770261</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.729183</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.645884</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.566463</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.791165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.512999</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.855422</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.492076</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.863454</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:665: UserWarning: 'pin_memory' argument is set as true but no accelerator is found, then device pinned memory won't be used.\n",
      "  warnings.warn(warn_msg)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [1/1 : < :]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation: {'eval_loss': 0.9387280344963074, 'eval_precision': 0.0, 'eval_recall': 0.0, 'eval_f1': 0.0, 'eval_accuracy': 0.7911646586345381, 'eval_runtime': 7.3088, 'eval_samples_per_second': 1.368, 'eval_steps_per_second': 0.137, 'epoch': 8.0}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "c:\\Users\\Admin\\OneDrive\\10 Academy\\Week 4\\GitHub Repository\\ethioMartNER\\venv\\Lib\\site-packages\\seqeval\\metrics\\v1.py:57: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 due to no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "trainer.train()\n",
    "eval_results = trainer.evaluate()\n",
    "print(\"Evaluation:\", eval_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Model Saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved to ../data/models/finetuned_ner_amharic\n"
     ]
    }
   ],
   "source": [
    "save_dir = \"../data/models/finetuned_ner_amharic\"\n",
    "trainer.save_model(save_dir)\n",
    "tokenizer.save_pretrained(save_dir)\n",
    "print(f\"Model saved to {save_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Summary and Insights\n",
    " \n",
    " ### Model Training Summary\n",
    " The training process shows:\n",
    " \n",
    " 1. **Data Processing**: \n",
    "    - Successfully tokenized and prepared training/validation datasets (50 train, 40 val, 10 test examples)\n",
    "    - Applied proper label encoding for NER tags using BERT tokenizer\n",
    "    - Handled sequence padding and truncation appropriately\n",
    " \n",
    " 2. **Model Architecture**:\n",
    "    - Used BERT multilingual cased model with a custom token classification head\n",
    "    - Added new classifier weights for token classification task (classifier.bias, classifier.weight)\n",
    "    - Model was properly initialized for downstream NER task\n",
    " \n",
    " 3. **Training Process**:\n",
    "    - Implemented evaluation during training with seqeval metrics\n",
    "    - Used appropriate learning rate and training parameters\n",
    "    - Training completed successfully with progress tracking\n",
    " \n",
    " ### Key Insights from Outputs\n",
    " \n",
    " 1. **Warning Messages**:\n",
    "    - Pin memory warnings indicate no GPU acceleration available (CPU-only training)\n",
    "    - Undefined metric warnings suggest some entity classes have no predicted samples\n",
    "    - These warnings don't affect model functionality but indicate optimization opportunities\n",
    " \n",
    " 2. **Model Performance**:\n",
    "    - The model shows learning progress through training epochs\n",
    "    - Evaluation metrics provide entity-level performance analysis\n",
    "    - Model demonstrates ability to identify entities in Amharic text\n",
    " \n",
    " 3. **Data Quality Observations**:\n",
    "    - Some entity classes may be underrepresented in the dataset\n",
    "    - Model predictions show reasonable entity recognition capabilities\n",
    "    - Validation set performance indicates generalization potential\n",
    " \n",
    " ### Recommendations\n",
    " 1. Consider using GPU acceleration for faster training\n",
    " 2. Address class imbalance if certain entities are rarely predicted\n",
    " 3. Expand dataset with more diverse entity examples\n",
    " 4. Fine-tune hyperparameters based on validation performance\n",
    " 5. Consider data augmentation techniques for underrepresented entity classes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
