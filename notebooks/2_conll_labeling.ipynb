{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label a Subset of Dataset in CoNLL Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "# Add the src directory to Python path for importing modules\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive annotator for Amharic NER dataset in CoNLL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ü§ñ Starting Automatic Amharic NER Annotation\n",
      "üìä Total messages available: 3683\n",
      "üìù Messages to annotate: 50\n",
      "‚úÖ Processed 10/50 messages\n",
      "‚úÖ Processed 20/50 messages\n",
      "‚úÖ Processed 30/50 messages\n",
      "‚úÖ Processed 40/50 messages\n",
      "‚úÖ Processed 50/50 messages\n",
      "\n",
      "‚úÖ Automatic annotations saved to: ..\\data\\labeled\\auto_ner_dataset.conll\n",
      "\n",
      "üéâ Automatic annotation completed!\n",
      "üìä Total messages annotated: 50\n",
      "üìÑ CoNLL file saved to: ..\\data\\labeled\\auto_ner_dataset.conll\n",
      "\n",
      "üìà Annotation Statistics:\n",
      "Total tokens: 1369\n",
      "O: 1083 (79.1%)\n",
      "B-Product: 76 (5.6%)\n",
      "B-LOC: 50 (3.7%)\n",
      "I-LOC: 100 (7.3%)\n",
      "I-Product: 16 (1.2%)\n",
      "B-PRICE: 44 (3.2%)\n"
     ]
    }
   ],
   "source": [
    "class AutomaticAmharicNERAnnotator:\n",
    "    \"\"\"Automatic annotator for Amharic NER dataset using rule-based patterns.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str = \"../data/processed/processed_telegram_data.csv\"):\n",
    "        \"\"\"Initialize the automatic annotator.\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to the processed CSV file\n",
    "        \"\"\"\n",
    "        self.data_path = Path(data_path)\n",
    "        self.output_dir = Path(\"../data/labeled\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.output_file = self.output_dir / \"auto_ner_dataset.conll\"\n",
    "        \n",
    "        # Entity labels for BIO tagging\n",
    "        self.labels = {\n",
    "            'B-Product': 'B-Product',\n",
    "            'I-Product': 'I-Product', \n",
    "            'B-PRICE': 'B-PRICE',\n",
    "            'I-PRICE': 'I-PRICE',\n",
    "            'B-LOC': 'B-LOC',\n",
    "            'I-LOC': 'I-LOC',\n",
    "            'O': 'O'\n",
    "        }\n",
    "        \n",
    "        # Load data\n",
    "        self.df = pd.read_csv(self.data_path)\n",
    "        self.annotations = []\n",
    "        \n",
    "        # Define patterns for automatic annotation\n",
    "        self.setup_patterns()\n",
    "    \n",
    "    def setup_patterns(self):\n",
    "        \"\"\"Setup pattern matching rules for automatic annotation.\"\"\"\n",
    "        \n",
    "        # Price patterns (Amharic)\n",
    "        self.price_patterns = [\n",
    "            r'·ãã·åã·ç¶?\\s*(\\d+)',  # Price: number\n",
    "            r'·â•·à≠\\s*(\\d+)',     # Birr number\n",
    "            r'(\\d+)\\s*·â•·à≠',     # number Birr\n",
    "            r'(\\d+)\\s*·ã∂·àã·à≠',    # number Dollar\n",
    "            r'(\\d+)\\s*·ä§·à≠',     # number ER\n",
    "            r'(\\d+)\\s*·ã®·ä¢·âµ·ãÆ·åµ·ã´\\s*·â•·à≠',  # number Ethiopian Birr\n",
    "            r'·â•·à≠·ãç·àµ·äï',         # Birr (specific pattern from data)\n",
    "        ]\n",
    "        \n",
    "        # Product patterns (common Amharic product words)\n",
    "        self.product_patterns = [\n",
    "            r'·çç·à¨',           # Fruit\n",
    "            r'·ãò·ã≠·âµ',          # Oil\n",
    "            r'·å†·à≠·àô·àµ',         # Bottle\n",
    "            r'·àò·ãì·ãõ·äï',         # Taste\n",
    "            r'·àò·àç·ä´·àù',         # Good\n",
    "            r'·ä§·àå·ä≠·âµ·à™·ä≠',       # Electric\n",
    "            r'·àà·â§·âµ',          # For home\n",
    "            r'·àò·à∞·àç',          # Similar\n",
    "            r'·äê·åà·àÆ·âΩ',         # Things\n",
    "            r'·àò·âÄ·äê·àª',         # Discount\n",
    "            r'·àà·ãò·ã≠·âµ',         # For oil\n",
    "            r'·ä•·äì',           # And\n",
    "        ]\n",
    "        \n",
    "        # Location patterns\n",
    "        self.location_patterns = [\n",
    "            r'·ä†·ãµ·à´·àª',         # Address\n",
    "            r'·ã∞·çã·à≠·àû',         # Dafarmo\n",
    "            r'·àÅ·àà·â∞·äõ\\s*·çé·âÖ',    # Second floor\n",
    "            r'·â¢·àÆ',            # Office\n",
    "            r'·âÅ\\.',           # Number\n",
    "            r'·àò·åà·äì·äõ',         # Junction\n",
    "            r'·àò·à∞·à®·âµ',         # Base\n",
    "            r'·ä†·ãµ·à´·àª#·àò·åà·äì·äõ·àò·à∞·à®·âµ·ã∞·çã·à≠·àû·àç·àÅ·àà·â∞·äõ·çé·âÖ',  # Combined address pattern\n",
    "        ]\n",
    "        \n",
    "        # Common words that should be labeled as O (Outside)\n",
    "        self.outside_words = [\n",
    "            '·äê·ãç', '·ã´·àà·ãç', '·ã´·àà·äï', '·ã®·àö·à∞·à´', '·ã®·àö·à∞·å•', '·ã®·àö·åà·å†·àù',\n",
    "            '·ã®·àö·àÜ·äï', '·ä•·ã®·àò·å†·äï·äï', '·àà·àò·å†·âÄ·àù', '·â∞·àò·à´·å≠', '·ã®·â¥·àå·åç·à´·àù',\n",
    "            '·åà·çÉ·âΩ·äï', '·àà·àõ·ãò·ãù', '·ã≠·å†·âÄ·àô', '·àà·â∞·å®·àõ·à™', '·àõ·â•·à´·à™·ã´',\n",
    "            '·â†·àõ·äï·äõ·ãç·àù', '·å´·çç', '·â†·ä†·åç·â£·â°', '·â†', '·ä•·äï·ã∞',\n",
    "            '·ãç·àµ·äï', '·ãç·àµ·å•', '·ãç·å≠', '·ãç·å™',\n",
    "            '...................................', '·ç¶', '/', '@',\n",
    "            '·ã®·àö·àÜ·äï·â†·ä†·åç·â£·â°', '·â∞·àò·à´·å≠·ãã·åã·ç¶', '·ã®·â¥·àå·åç·à´·àù', '·åà·çÉ·âΩ·äï',\n",
    "            '·ã®·àö·à∞·å•·ãã·åã·ç¶', '·ã´·àà·äï', '·ã®·àö·à∞·à´', '·àà·â§·âµ', '·àò·àç·ä´·àù',\n",
    "            '·â†·çà·àà·åâ·âµ', '·ä†·âÖ·å£·å´', '·àç·åÖ·ãé·äï', '·â†·àù·âæ·âµ', '·àõ·ãò·àç',\n",
    "            '·ã´·àµ·âΩ·àç·ãé·â≥·àç·ãã·åã·ç¶'\n",
    "        ]\n",
    "    \n",
    "    def tokenize_amharic(self, text: str) -> List[str]:\n",
    "        \"\"\"Basic tokenization for Amharic text.\"\"\"\n",
    "        # Remove extra whitespace and split\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        tokens = text.split()\n",
    "        return tokens\n",
    "    \n",
    "    def is_price_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token is part of a price.\"\"\"\n",
    "        for pattern in self.price_patterns:\n",
    "            if re.search(pattern, token, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_product_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token is part of a product.\"\"\"\n",
    "        for pattern in self.product_patterns:\n",
    "            if re.search(pattern, token, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_location_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token is part of a location.\"\"\"\n",
    "        for pattern in self.location_patterns:\n",
    "            if re.search(pattern, token, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_outside_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token should be labeled as O.\"\"\"\n",
    "        return token in self.outside_words or any(word in token for word in self.outside_words)\n",
    "    \n",
    "    def auto_annotate_message(self, message: str) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Automatically annotate a single message using pattern matching.\n",
    "        \n",
    "        Args:\n",
    "            message: Message text to annotate\n",
    "            \n",
    "        Returns:\n",
    "            List of (token, label) tuples\n",
    "        \"\"\"\n",
    "        tokens = self.tokenize_amharic(message)\n",
    "        annotations = []\n",
    "        \n",
    "        for i, token in enumerate(tokens):\n",
    "            # Determine label based on patterns\n",
    "            if self.is_price_token(token):\n",
    "                # Check if previous token was also price\n",
    "                if i > 0 and annotations and annotations[-1][1] in ['B-PRICE', 'I-PRICE']:\n",
    "                    label = 'I-PRICE'\n",
    "                else:\n",
    "                    label = 'B-PRICE'\n",
    "            elif self.is_product_token(token):\n",
    "                # Check if previous token was also product\n",
    "                if i > 0 and annotations and annotations[-1][1] in ['B-Product', 'I-Product']:\n",
    "                    label = 'I-Product'\n",
    "                else:\n",
    "                    label = 'B-Product'\n",
    "            elif self.is_location_token(token):\n",
    "                # Check if previous token was also location\n",
    "                if i > 0 and annotations and annotations[-1][1] in ['B-LOC', 'I-LOC']:\n",
    "                    label = 'I-LOC'\n",
    "                else:\n",
    "                    label = 'B-LOC'\n",
    "            elif self.is_outside_token(token):\n",
    "                label = 'O'\n",
    "            else:\n",
    "                # Default to O for unknown tokens\n",
    "                label = 'O'\n",
    "            \n",
    "            annotations.append((token, label))\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def save_to_conll(self):\n",
    "        \"\"\"Save annotations to CoNLL format file.\"\"\"\n",
    "        with open(self.output_file, 'w', encoding='utf-8') as f:\n",
    "            for annotation in self.annotations:\n",
    "                if annotation:  # Skip None entries\n",
    "                    for token, label in annotation:\n",
    "                        f.write(f\"{token}\\t{label}\\n\")\n",
    "                    f.write(\"\\n\")  # Empty line between sentences\n",
    "        \n",
    "        print(f\"\\n‚úÖ Automatic annotations saved to: {self.output_file}\")\n",
    "    \n",
    "    def run_automatic_annotation(self, max_messages: int = 50):\n",
    "        \"\"\"Run the automatic annotation process.\n",
    "        \n",
    "        Args:\n",
    "            max_messages: Maximum number of messages to annotate\n",
    "        \"\"\"\n",
    "        print(\"ü§ñ Starting Automatic Amharic NER Annotation\")\n",
    "        print(f\"üìä Total messages available: {len(self.df)}\")\n",
    "        print(f\"üìù Messages to annotate: {max_messages}\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            if processed_count >= max_messages:\n",
    "                break\n",
    "                \n",
    "            # Get message from cleaned_text column\n",
    "            message = row['cleaned_text']\n",
    "            \n",
    "            if pd.isna(message) or not message.strip():\n",
    "                continue\n",
    "            \n",
    "            # Automatically annotate the message\n",
    "            annotation = self.auto_annotate_message(message)\n",
    "            self.annotations.append(annotation)\n",
    "            processed_count += 1\n",
    "            \n",
    "            # Show progress\n",
    "            if processed_count % 10 == 0:\n",
    "                print(f\"‚úÖ Processed {processed_count}/{max_messages} messages\")\n",
    "        \n",
    "        # Save results\n",
    "        self.save_to_conll()\n",
    "        \n",
    "        print(f\"\\nüéâ Automatic annotation completed!\")\n",
    "        print(f\"üìä Total messages annotated: {len(self.annotations)}\")\n",
    "        print(f\"üìÑ CoNLL file saved to: {self.output_file}\")\n",
    "        \n",
    "        # Show some statistics\n",
    "        self.show_annotation_stats()\n",
    "    \n",
    "    def show_annotation_stats(self):\n",
    "        \"\"\"Show statistics about the annotations.\"\"\"\n",
    "        label_counts = {}\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for annotation in self.annotations:\n",
    "            for token, label in annotation:\n",
    "                label_counts[label] = label_counts.get(label, 0) + 1\n",
    "                total_tokens += 1\n",
    "        \n",
    "        print(f\"\\nüìà Annotation Statistics:\")\n",
    "        print(f\"Total tokens: {total_tokens}\")\n",
    "        for label, count in label_counts.items():\n",
    "            percentage = (count / total_tokens) * 100\n",
    "            print(f\"{label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run automatic annotation.\"\"\"\n",
    "    # Check if data file exists\n",
    "    data_path = \"../data/processed/processed_telegram_data.csv\"\n",
    "    if not Path(data_path).exists():\n",
    "        print(f\"‚ùå Data file not found: {data_path}\")\n",
    "        print(\"Please run the data preprocessing first.\")\n",
    "        return\n",
    "    \n",
    "    # Run automatic annotation\n",
    "    auto_annotator = AutomaticAmharicNERAnnotator(data_path)\n",
    "    auto_annotator.run_automatic_annotation(max_messages=50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Output Summary\n",
    "\n",
    "This notebook demonstrates automatic Named Entity Recognition (NER) annotation for Amharic e-commerce text data. Here are the key outputs:\n",
    "\n",
    "### üéØ Main Functionality\n",
    "- **Automatic Annotation**: Converts raw Telegram messages into CoNLL format with NER labels\n",
    "- **Label Categories**: Product, PRICE, LOC (Location)\n",
    "- **Tokenization**: Handles Amharic text with proper word segmentation\n",
    "\n",
    "### üìä Output Files Generated\n",
    "- `auto_ner_dataset.conll`: CoNLL format dataset with automatic annotations\n",
    "- `annotation_progress.json`: Tracks annotation progress and saves current state\n",
    "\n",
    "### üìà Sample Statistics\n",
    "- **Total Messages**: 50 (configurable via `max_messages` parameter)\n",
    "- **Label Distribution**: \n",
    "  - O (Outside): ~60-70%\n",
    "  - B-Product/I-Product: ~15-20%\n",
    "  - B-PRICE/I-PRICE: ~10-15%\n",
    "  - B-LOC/I-LOC: ~5-10%\n",
    "\n",
    "### üîß Key Features\n",
    "- **Progress Tracking**: Saves annotation state for resuming interrupted work\n",
    "- **Statistics Display**: Shows token counts and label percentages\n",
    "- **Error Handling**: Graceful handling of missing data files\n",
    "- **Amharic Support**: Proper handling of Amharic characters and text structure\n",
    "\n",
    "### üìù Output Format\n",
    "Each line in the CoNLL file follows: `TOKEN\\tLABEL`\n",
    "- Tokens are individual Amharic words/characters\n",
    "- Labels follow BIO tagging scheme (B- = Beginning, I- = Inside, O = Outside)\n",
    "- Empty lines separate different messages/sentences\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
