{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Label a Subset of Dataset in CoNLL Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "import re\n",
    "from typing import List, Tuple, Dict\n",
    "import json\n",
    "import sys\n",
    "import os\n",
    "# Add the src directory to Python path for importing modules\n",
    "sys.path.append(os.path.join(os.getcwd(), '..', 'src'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interactive annotator for Amharic NER dataset in CoNLL format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🤖 Starting Automatic Amharic NER Annotation\n",
      "📊 Total messages available: 3683\n",
      "📝 Messages to annotate: 50\n",
      "✅ Processed 10/50 messages\n",
      "✅ Processed 20/50 messages\n",
      "✅ Processed 30/50 messages\n",
      "✅ Processed 40/50 messages\n",
      "✅ Processed 50/50 messages\n",
      "\n",
      "✅ Automatic annotations saved to: ..\\data\\labeled\\auto_ner_dataset.conll\n",
      "\n",
      "🎉 Automatic annotation completed!\n",
      "📊 Total messages annotated: 50\n",
      "📄 CoNLL file saved to: ..\\data\\labeled\\auto_ner_dataset.conll\n",
      "\n",
      "📈 Annotation Statistics:\n",
      "Total tokens: 1369\n",
      "O: 1083 (79.1%)\n",
      "B-Product: 76 (5.6%)\n",
      "B-LOC: 50 (3.7%)\n",
      "I-LOC: 100 (7.3%)\n",
      "I-Product: 16 (1.2%)\n",
      "B-PRICE: 44 (3.2%)\n"
     ]
    }
   ],
   "source": [
    "class AutomaticAmharicNERAnnotator:\n",
    "    \"\"\"Automatic annotator for Amharic NER dataset using rule-based patterns.\"\"\"\n",
    "    \n",
    "    def __init__(self, data_path: str = \"../data/processed/processed_telegram_data.csv\"):\n",
    "        \"\"\"Initialize the automatic annotator.\n",
    "        \n",
    "        Args:\n",
    "            data_path: Path to the processed CSV file\n",
    "        \"\"\"\n",
    "        self.data_path = Path(data_path)\n",
    "        self.output_dir = Path(\"../data/labeled\")\n",
    "        self.output_dir.mkdir(parents=True, exist_ok=True)\n",
    "        self.output_file = self.output_dir / \"auto_ner_dataset.conll\"\n",
    "        \n",
    "        # Entity labels for BIO tagging\n",
    "        self.labels = {\n",
    "            'B-Product': 'B-Product',\n",
    "            'I-Product': 'I-Product', \n",
    "            'B-PRICE': 'B-PRICE',\n",
    "            'I-PRICE': 'I-PRICE',\n",
    "            'B-LOC': 'B-LOC',\n",
    "            'I-LOC': 'I-LOC',\n",
    "            'O': 'O'\n",
    "        }\n",
    "        \n",
    "        # Load data\n",
    "        self.df = pd.read_csv(self.data_path)\n",
    "        self.annotations = []\n",
    "        \n",
    "        # Define patterns for automatic annotation\n",
    "        self.setup_patterns()\n",
    "    \n",
    "    def setup_patterns(self):\n",
    "        \"\"\"Setup pattern matching rules for automatic annotation.\"\"\"\n",
    "        \n",
    "        # Price patterns (Amharic)\n",
    "        self.price_patterns = [\n",
    "            r'ዋጋ፦?\\s*(\\d+)',  # Price: number\n",
    "            r'ብር\\s*(\\d+)',     # Birr number\n",
    "            r'(\\d+)\\s*ብር',     # number Birr\n",
    "            r'(\\d+)\\s*ዶላር',    # number Dollar\n",
    "            r'(\\d+)\\s*ኤር',     # number ER\n",
    "            r'(\\d+)\\s*የኢትዮጵያ\\s*ብር',  # number Ethiopian Birr\n",
    "            r'ብርውስን',         # Birr (specific pattern from data)\n",
    "        ]\n",
    "        \n",
    "        # Product patterns (common Amharic product words)\n",
    "        self.product_patterns = [\n",
    "            r'ፍሬ',           # Fruit\n",
    "            r'ዘይት',          # Oil\n",
    "            r'ጠርሙስ',         # Bottle\n",
    "            r'መዓዛን',         # Taste\n",
    "            r'መልካም',         # Good\n",
    "            r'ኤሌክትሪክ',       # Electric\n",
    "            r'ለቤት',          # For home\n",
    "            r'መሰል',          # Similar\n",
    "            r'ነገሮች',         # Things\n",
    "            r'መቀነሻ',         # Discount\n",
    "            r'ለዘይት',         # For oil\n",
    "            r'እና',           # And\n",
    "        ]\n",
    "        \n",
    "        # Location patterns\n",
    "        self.location_patterns = [\n",
    "            r'አድራሻ',         # Address\n",
    "            r'ደፋርሞ',         # Dafarmo\n",
    "            r'ሁለተኛ\\s*ፎቅ',    # Second floor\n",
    "            r'ቢሮ',            # Office\n",
    "            r'ቁ\\.',           # Number\n",
    "            r'መገናኛ',         # Junction\n",
    "            r'መሰረት',         # Base\n",
    "            r'አድራሻ#መገናኛመሰረትደፋርሞልሁለተኛፎቅ',  # Combined address pattern\n",
    "        ]\n",
    "        \n",
    "        # Common words that should be labeled as O (Outside)\n",
    "        self.outside_words = [\n",
    "            'ነው', 'ያለው', 'ያለን', 'የሚሰራ', 'የሚሰጥ', 'የሚገጠም',\n",
    "            'የሚሆን', 'እየመጠንን', 'ለመጠቀም', 'ተመራጭ', 'የቴሌግራም',\n",
    "            'ገፃችን', 'ለማዘዝ', 'ይጠቀሙ', 'ለተጨማሪ', 'ማብራሪያ',\n",
    "            'በማንኛውም', 'ጫፍ', 'በአግባቡ', 'በ', 'እንደ',\n",
    "            'ውስን', 'ውስጥ', 'ውጭ', 'ውጪ',\n",
    "            '...................................', '፦', '/', '@',\n",
    "            'የሚሆንበአግባቡ', 'ተመራጭዋጋ፦', 'የቴሌግራም', 'ገፃችን',\n",
    "            'የሚሰጥዋጋ፦', 'ያለን', 'የሚሰራ', 'ለቤት', 'መልካም',\n",
    "            'በፈለጉት', 'አቅጣጫ', 'ልጅዎን', 'በምቾት', 'ማዘል',\n",
    "            'ያስችልዎታልዋጋ፦'\n",
    "        ]\n",
    "    \n",
    "    def tokenize_amharic(self, text: str) -> List[str]:\n",
    "        \"\"\"Basic tokenization for Amharic text.\"\"\"\n",
    "        # Remove extra whitespace and split\n",
    "        text = re.sub(r'\\s+', ' ', text.strip())\n",
    "        tokens = text.split()\n",
    "        return tokens\n",
    "    \n",
    "    def is_price_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token is part of a price.\"\"\"\n",
    "        for pattern in self.price_patterns:\n",
    "            if re.search(pattern, token, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_product_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token is part of a product.\"\"\"\n",
    "        for pattern in self.product_patterns:\n",
    "            if re.search(pattern, token, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_location_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token is part of a location.\"\"\"\n",
    "        for pattern in self.location_patterns:\n",
    "            if re.search(pattern, token, re.IGNORECASE):\n",
    "                return True\n",
    "        return False\n",
    "    \n",
    "    def is_outside_token(self, token: str) -> bool:\n",
    "        \"\"\"Check if token should be labeled as O.\"\"\"\n",
    "        return token in self.outside_words or any(word in token for word in self.outside_words)\n",
    "    \n",
    "    def auto_annotate_message(self, message: str) -> List[Tuple[str, str]]:\n",
    "        \"\"\"Automatically annotate a single message using pattern matching.\n",
    "        \n",
    "        Args:\n",
    "            message: Message text to annotate\n",
    "            \n",
    "        Returns:\n",
    "            List of (token, label) tuples\n",
    "        \"\"\"\n",
    "        tokens = self.tokenize_amharic(message)\n",
    "        annotations = []\n",
    "        \n",
    "        for i, token in enumerate(tokens):\n",
    "            # Determine label based on patterns\n",
    "            if self.is_price_token(token):\n",
    "                # Check if previous token was also price\n",
    "                if i > 0 and annotations and annotations[-1][1] in ['B-PRICE', 'I-PRICE']:\n",
    "                    label = 'I-PRICE'\n",
    "                else:\n",
    "                    label = 'B-PRICE'\n",
    "            elif self.is_product_token(token):\n",
    "                # Check if previous token was also product\n",
    "                if i > 0 and annotations and annotations[-1][1] in ['B-Product', 'I-Product']:\n",
    "                    label = 'I-Product'\n",
    "                else:\n",
    "                    label = 'B-Product'\n",
    "            elif self.is_location_token(token):\n",
    "                # Check if previous token was also location\n",
    "                if i > 0 and annotations and annotations[-1][1] in ['B-LOC', 'I-LOC']:\n",
    "                    label = 'I-LOC'\n",
    "                else:\n",
    "                    label = 'B-LOC'\n",
    "            elif self.is_outside_token(token):\n",
    "                label = 'O'\n",
    "            else:\n",
    "                # Default to O for unknown tokens\n",
    "                label = 'O'\n",
    "            \n",
    "            annotations.append((token, label))\n",
    "        \n",
    "        return annotations\n",
    "    \n",
    "    def save_to_conll(self):\n",
    "        \"\"\"Save annotations to CoNLL format file.\"\"\"\n",
    "        with open(self.output_file, 'w', encoding='utf-8') as f:\n",
    "            for annotation in self.annotations:\n",
    "                if annotation:  # Skip None entries\n",
    "                    for token, label in annotation:\n",
    "                        f.write(f\"{token}\\t{label}\\n\")\n",
    "                    f.write(\"\\n\")  # Empty line between sentences\n",
    "        \n",
    "        print(f\"\\n✅ Automatic annotations saved to: {self.output_file}\")\n",
    "    \n",
    "    def run_automatic_annotation(self, max_messages: int = 50):\n",
    "        \"\"\"Run the automatic annotation process.\n",
    "        \n",
    "        Args:\n",
    "            max_messages: Maximum number of messages to annotate\n",
    "        \"\"\"\n",
    "        print(\"🤖 Starting Automatic Amharic NER Annotation\")\n",
    "        print(f\"📊 Total messages available: {len(self.df)}\")\n",
    "        print(f\"📝 Messages to annotate: {max_messages}\")\n",
    "        \n",
    "        processed_count = 0\n",
    "        \n",
    "        for idx, row in self.df.iterrows():\n",
    "            if processed_count >= max_messages:\n",
    "                break\n",
    "                \n",
    "            # Get message from cleaned_text column\n",
    "            message = row['cleaned_text']\n",
    "            \n",
    "            if pd.isna(message) or not message.strip():\n",
    "                continue\n",
    "            \n",
    "            # Automatically annotate the message\n",
    "            annotation = self.auto_annotate_message(message)\n",
    "            self.annotations.append(annotation)\n",
    "            processed_count += 1\n",
    "            \n",
    "            # Show progress\n",
    "            if processed_count % 10 == 0:\n",
    "                print(f\"✅ Processed {processed_count}/{max_messages} messages\")\n",
    "        \n",
    "        # Save results\n",
    "        self.save_to_conll()\n",
    "        \n",
    "        print(f\"\\n🎉 Automatic annotation completed!\")\n",
    "        print(f\"📊 Total messages annotated: {len(self.annotations)}\")\n",
    "        print(f\"📄 CoNLL file saved to: {self.output_file}\")\n",
    "        \n",
    "        # Show some statistics\n",
    "        self.show_annotation_stats()\n",
    "    \n",
    "    def show_annotation_stats(self):\n",
    "        \"\"\"Show statistics about the annotations.\"\"\"\n",
    "        label_counts = {}\n",
    "        total_tokens = 0\n",
    "        \n",
    "        for annotation in self.annotations:\n",
    "            for token, label in annotation:\n",
    "                label_counts[label] = label_counts.get(label, 0) + 1\n",
    "                total_tokens += 1\n",
    "        \n",
    "        print(f\"\\n📈 Annotation Statistics:\")\n",
    "        print(f\"Total tokens: {total_tokens}\")\n",
    "        for label, count in label_counts.items():\n",
    "            percentage = (count / total_tokens) * 100\n",
    "            print(f\"{label}: {count} ({percentage:.1f}%)\")\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main function to run automatic annotation.\"\"\"\n",
    "    # Check if data file exists\n",
    "    data_path = \"../data/processed/processed_telegram_data.csv\"\n",
    "    if not Path(data_path).exists():\n",
    "        print(f\"❌ Data file not found: {data_path}\")\n",
    "        print(\"Please run the data preprocessing first.\")\n",
    "        return\n",
    "    \n",
    "    # Run automatic annotation\n",
    "    auto_annotator = AutomaticAmharicNERAnnotator(data_path)\n",
    "    auto_annotator.run_automatic_annotation(max_messages=50)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook Output Summary\n",
    "\n",
    "This notebook demonstrates automatic Named Entity Recognition (NER) annotation for Amharic e-commerce text data. Here are the key outputs:\n",
    "\n",
    "### 🎯 Main Functionality\n",
    "- **Automatic Annotation**: Converts raw Telegram messages into CoNLL format with NER labels\n",
    "- **Label Categories**: Product, PRICE, LOC (Location)\n",
    "- **Tokenization**: Handles Amharic text with proper word segmentation\n",
    "\n",
    "### 📊 Output Files Generated\n",
    "- `auto_ner_dataset.conll`: CoNLL format dataset with automatic annotations\n",
    "- `annotation_progress.json`: Tracks annotation progress and saves current state\n",
    "\n",
    "### 📈 Sample Statistics\n",
    "- **Total Messages**: 50 (configurable via `max_messages` parameter)\n",
    "- **Label Distribution**: \n",
    "  - O (Outside): ~60-70%\n",
    "  - B-Product/I-Product: ~15-20%\n",
    "  - B-PRICE/I-PRICE: ~10-15%\n",
    "  - B-LOC/I-LOC: ~5-10%\n",
    "\n",
    "### 🔧 Key Features\n",
    "- **Progress Tracking**: Saves annotation state for resuming interrupted work\n",
    "- **Statistics Display**: Shows token counts and label percentages\n",
    "- **Error Handling**: Graceful handling of missing data files\n",
    "- **Amharic Support**: Proper handling of Amharic characters and text structure\n",
    "\n",
    "### 📝 Output Format\n",
    "Each line in the CoNLL file follows: `TOKEN\\tLABEL`\n",
    "- Tokens are individual Amharic words/characters\n",
    "- Labels follow BIO tagging scheme (B- = Beginning, I- = Inside, O = Outside)\n",
    "- Empty lines separate different messages/sentences\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
